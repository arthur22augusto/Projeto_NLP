{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b490e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies\n",
    "#!pip -q install transformers torch accelerate tqdm\n",
    "\n",
    "# Importing dependencies\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5afbe4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the sample data\n",
    "data_sample = pd.read_csv('../data/raw/sample/twcs_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80895acc",
   "metadata": {},
   "source": [
    "## Creating target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab735420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computando conversation_id: 100%|██████████| 100000/100000 [00:00<00:00, 508838.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting tweet_id and in_response_to_tweet_id to Int64\n",
    "data_sample['tweet_id'] = pd.to_numeric(\n",
    "    data_sample['tweet_id'], errors='coerce'\n",
    ").astype('Int64')\n",
    "\n",
    "data_sample['in_response_to_tweet_id'] = pd.to_numeric(\n",
    "    data_sample['in_response_to_tweet_id'], errors='coerce'\n",
    ").astype('Int64')\n",
    "\n",
    "# Creating a dictionary to map the relation between tweet_id and in_response_to_tweet_id\n",
    "parent_of = dict(\n",
    "    data_sample[['tweet_id', 'in_response_to_tweet_id']]\n",
    "    .dropna().to_numpy()\n",
    ")\n",
    "\n",
    "\n",
    "# Root of conversation = last message of the conversation\n",
    "root_cache = {}\n",
    "\n",
    "def get_root(tid, max_steps=50):\n",
    "    x = tid\n",
    "    path = []\n",
    "    steps = 0\n",
    "    while True:\n",
    "        if x in root_cache:\n",
    "            root = root_cache[x]\n",
    "            break\n",
    "        parent = parent_of.get(x, np.nan)\n",
    "        if pd.isna(parent) or parent not in parent_of:\n",
    "            root = x\n",
    "            break\n",
    "        if steps >= max_steps:  # proteção a ciclos/threads longas\n",
    "            root = x\n",
    "            break\n",
    "        path.append(x)\n",
    "        x = parent\n",
    "        steps += 1\n",
    "    for p in path:\n",
    "        root_cache[p] = root\n",
    "    return root\n",
    "\n",
    "tqdm.pandas(desc='Computando conversation_id')\n",
    "data_sample['conversation_id'] = data_sample['tweet_id'].progress_apply(\n",
    "    get_root\n",
    ").astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "216f9b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Threads: {np.int64(1362465): 3, np.int64(604512): 3, np.int64(732556): 3, np.int64(1226215): 3, np.int64(1108746): 3, np.int64(525592): 3, np.int64(1053383): 3, np.int64(1034144): 3, np.int64(43407): 3, np.int64(858798): 3}\n",
      "\n",
      "Example:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>author_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66886</th>\n",
       "      <td>1362465</td>\n",
       "      <td>1362465</td>\n",
       "      <td>True</td>\n",
       "      <td>119972</td>\n",
       "      <td>1362466</td>\n",
       "      <td>Fri Oct 27 20:35:38 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90491</th>\n",
       "      <td>1362465</td>\n",
       "      <td>1362463</td>\n",
       "      <td>False</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>1362465</td>\n",
       "      <td>Fri Oct 27 20:38:00 +0000 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76581</th>\n",
       "      <td>1362465</td>\n",
       "      <td>1362464</td>\n",
       "      <td>True</td>\n",
       "      <td>119972</td>\n",
       "      <td>1362463</td>\n",
       "      <td>Fri Oct 27 20:40:00 +0000 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id  tweet_id  inbound   author_id  \\\n",
       "66886          1362465   1362465     True      119972   \n",
       "90491          1362465   1362463    False  AmazonHelp   \n",
       "76581          1362465   1362464     True      119972   \n",
       "\n",
       "       in_response_to_tweet_id                      created_at  \n",
       "66886                  1362466  Fri Oct 27 20:35:38 +0000 2017  \n",
       "90491                  1362465  Fri Oct 27 20:38:00 +0000 2017  \n",
       "76581                  1362463  Fri Oct 27 20:40:00 +0000 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation of the conversation_id column\n",
    "\n",
    "tam = (data_sample.groupby('conversation_id')['tweet_id']\n",
    "       .size().sort_values(ascending=False))\n",
    "print('Big Threads:', tam.head(10).to_dict())\n",
    "\n",
    "ex_conv = tam.index[0]\n",
    "print('\\nExample:')\n",
    "cols = ['conversation_id', 'tweet_id', 'inbound', 'author_id',\n",
    "        'in_response_to_tweet_id', 'created_at']\n",
    "display(data_sample.loc[\n",
    "    data_sample['conversation_id'] == ex_conv, cols\n",
    "].sort_values('created_at').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16fa397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_13768\\343412660.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_sample['created_at'] = pd.to_datetime(data_sample['created_at'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novas features de tempo (resumo):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_duration_minutes</th>\n",
       "      <th>time_to_first_response_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.862200e+04</td>\n",
       "      <td>591.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.662273e+01</td>\n",
       "      <td>204.999351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.565895e+03</td>\n",
       "      <td>737.251264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>76.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.114589e+06</td>\n",
       "      <td>9958.483333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_duration_minutes  time_to_first_response_minutes\n",
       "count            9.862200e+04                      591.000000\n",
       "mean             1.662273e+01                      204.999351\n",
       "std              3.565895e+03                      737.251264\n",
       "min              0.000000e+00                        0.516667\n",
       "25%              0.000000e+00                        4.925000\n",
       "50%              0.000000e+00                       16.200000\n",
       "75%              0.000000e+00                       76.558333\n",
       "max              1.114589e+06                     9958.483333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nPrimeiras linhas das novas features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_duration_minutes</th>\n",
       "      <th>time_to_first_response_minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_duration_minutes  time_to_first_response_minutes\n",
       "conversation_id                                                        \n",
       "1                                   0.0                             NaN\n",
       "12                                  0.0                             NaN\n",
       "69                                  0.0                             NaN\n",
       "84                                  0.0                             NaN\n",
       "93                                  0.0                             NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering de Tempo de Atendimento\n",
    "data_sample['created_at'] = pd.to_datetime(data_sample['created_at'], errors='coerce')\n",
    "\n",
    "# Garante ordenação por tempo\n",
    "data_sample_sorted = data_sample.sort_values(['conversation_id', 'created_at'])\n",
    "\n",
    "# Duração total da conversa\n",
    "conv_aggs = data_sample_sorted.groupby('conversation_id')['created_at'].agg(['min', 'max'])\n",
    "conv_aggs['total_duration_minutes'] = (\n",
    "    (conv_aggs['max'] - conv_aggs['min']).dt.total_seconds() / 60.0\n",
    ")\n",
    "\n",
    "# Tempo para primeira resposta\n",
    "first_inbound = (\n",
    "    data_sample_sorted[data_sample_sorted['inbound']]\n",
    "    .groupby('conversation_id')['created_at'].first()\n",
    ")\n",
    "first_outbound = (\n",
    "    data_sample_sorted[~data_sample_sorted['inbound']]\n",
    "    .groupby('conversation_id')['created_at'].first()\n",
    ")\n",
    "\n",
    "# Junta as features de tempo\n",
    "conv_features = pd.DataFrame(conv_aggs[['total_duration_minutes']])\n",
    "conv_features = conv_features.merge(\n",
    "    first_inbound.rename('first_inbound'),\n",
    "    left_index=True, right_index=True, how='left'\n",
    ")\n",
    "conv_features = conv_features.merge(\n",
    "    first_outbound.rename('first_outbound'),\n",
    "    left_index=True, right_index=True, how='left'\n",
    ")\n",
    "\n",
    "# Calcula o tempo de resposta\n",
    "conv_features['time_to_first_response_minutes'] = (\n",
    "    (conv_features['first_outbound'] - conv_features['first_inbound'])\n",
    "    .dt.total_seconds() / 60.0\n",
    ")\n",
    "\n",
    "# Remove valores negativos (possivelmente por dados incorretos)\n",
    "conv_features.loc[conv_features['time_to_first_response_minutes'] < 0,\n",
    "                  'time_to_first_response_minutes'] = np.nan\n",
    "\n",
    "# Seleciona colunas finais e exibe estatísticas\n",
    "conv_features = conv_features[\n",
    "    ['total_duration_minutes', 'time_to_first_response_minutes']\n",
    "]\n",
    "\n",
    "print(\"Novas features de tempo (resumo):\")\n",
    "display(conv_features.describe())\n",
    "print(\"\\\\nPrimeiras linhas das novas features:\")\n",
    "display(conv_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d4812d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns: {'conv_col': 'conversation_id', 'text_col': 'text'}\n"
     ]
    }
   ],
   "source": [
    "# Normalize datetime\n",
    "data_sample['created_at'] = pd.to_datetime(\n",
    "    data_sample['created_at'], utc=True, errors='coerce'\n",
    ")\n",
    "\n",
    "# Detect text column\n",
    "text_col = ['text']\n",
    "# Detect conversation column\n",
    "conv_col = 'conversation_id'\n",
    "\n",
    "if conv_col not in data_sample.columns:\n",
    "    raise ValueError('No conversation_id in data_sample.')\n",
    "\n",
    "\n",
    "text_col = ['text']\n",
    "\n",
    "try:\n",
    "    text_col\n",
    "except NameError:\n",
    "    text_col = None\n",
    "\n",
    "if isinstance(text_col, (list, tuple, np.ndarray, pd.Index)):\n",
    "    text_col = next(\n",
    "        (c for c in text_col if c in data_sample.columns),\n",
    "        None\n",
    "    )\n",
    "\n",
    "if not isinstance(text_col, str) or text_col not in data_sample.columns:\n",
    "    text_col = next(\n",
    "        (c for c in text_col if c in data_sample.columns),\n",
    "        None\n",
    "    )\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError('No text column in data_sample.')\n",
    "\n",
    "print('Using columns:',\n",
    "      {'conv_col': conv_col, 'text_col': text_col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca1731ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-10-31 22:04:47+00:00</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>2017-10-31 22:03:32+00:00</td>\n",
       "      <td>@ChipotleTweets messed up today and didn’t giv...</td>\n",
       "      <td>@ChipotleTweets messed up today and didn’t giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>2017-11-01 01:23:03+00:00</td>\n",
       "      <td>@ChipotleTweets are they supposed to charge pp...</td>\n",
       "      <td>@ChipotleTweets are they supposed to charge pp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  tweet_id                created_at  \\\n",
       "0               12        12 2017-10-31 22:04:47+00:00   \n",
       "1               69        69 2017-10-31 22:03:32+00:00   \n",
       "2               84        84 2017-11-01 01:23:03+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  @sprintcare You gonna magically change your co...   \n",
       "1  @ChipotleTweets messed up today and didn’t giv...   \n",
       "2  @ChipotleTweets are they supposed to charge pp...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  @sprintcare You gonna magically change your co...  \n",
       "1  @ChipotleTweets messed up today and didn’t giv...  \n",
       "2  @ChipotleTweets are they supposed to charge pp...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the last tweet of the conversation\n",
    "data_sample['created_at'] = pd.to_datetime(\n",
    "    data_sample['created_at'], utc=True, errors='coerce'\n",
    ")\n",
    "\n",
    "df_cli = data_sample.loc[\n",
    "    data_sample['inbound'] == True,\n",
    "    [conv_col, 'tweet_id', 'created_at', text_col]\n",
    "].copy()\n",
    "\n",
    "df_cli = df_cli.sort_values([conv_col, 'created_at'])\n",
    "idx_last = df_cli.groupby(conv_col)['created_at'].idxmax()\n",
    "ultimo_cliente = df_cli.loc[idx_last].reset_index(drop=True)\n",
    "\n",
    "ultimo_cliente['text_clean'] = (\n",
    "    ultimo_cliente[text_col].astype(str)\n",
    "    .str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    ")\n",
    "\n",
    "ultimo_cliente = ultimo_cliente.loc[\n",
    "    ultimo_cliente['text_clean'].str.len() > 0\n",
    "].reset_index(drop=True)\n",
    "\n",
    "ultimo_cliente.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79804931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas após o merge:\n",
      "Index(['conversation_id', 'tweet_id', 'created_at', 'text', 'text_clean',\n",
      "       'total_duration_minutes', 'time_to_first_response_minutes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_duration_minutes</th>\n",
       "      <th>time_to_first_response_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.459800e+04</td>\n",
       "      <td>591.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.001029e+01</td>\n",
       "      <td>204.999351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.792531e+03</td>\n",
       "      <td>737.251264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>16.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>76.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.114589e+06</td>\n",
       "      <td>9958.483333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_duration_minutes  time_to_first_response_minutes\n",
       "count            5.459800e+04                      591.000000\n",
       "mean             3.001029e+01                      204.999351\n",
       "std              4.792531e+03                      737.251264\n",
       "min              0.000000e+00                        0.516667\n",
       "25%              0.000000e+00                        4.925000\n",
       "50%              0.000000e+00                       16.200000\n",
       "75%              0.000000e+00                       76.558333\n",
       "max              1.114589e+06                     9958.483333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge com as features de tempo\n",
    "ultimo_cliente = ultimo_cliente.merge(\n",
    "    conv_features,\n",
    "    left_on='conversation_id',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Colunas após o merge:\")\n",
    "print(ultimo_cliente.columns)\n",
    "display(ultimo_cliente[['total_duration_minutes', 'time_to_first_response_minutes']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42aabbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading sentiment analysis pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "sentiment = pipeline(\n",
    "    task='sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b31409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1707/1707 [58:39<00:00,  2.06s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>sent_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>1 star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id sent_label  sent_stars\n",
       "0        12    5 stars           5\n",
       "1        69     1 star           1\n",
       "2        84     1 star           1\n",
       "3        93    3 stars           3\n",
       "4       149     1 star           1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferring sentiment in batches\n",
    "def batched_idx(index, batch_size=32):\n",
    "    arr = index.to_list()\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        yield arr[i:i+batch_size]\n",
    "\n",
    "preds = []\n",
    "indices = ultimo_cliente.index\n",
    "for chunk in tqdm(batched_idx(indices, 32), total=math.ceil(len(indices)/32)):\n",
    "    texts = ultimo_cliente.loc[chunk, 'text_clean'].tolist()\n",
    "    out = sentiment(texts, truncation=True)\n",
    "    preds.extend(out)\n",
    "\n",
    "pred_df = pd.DataFrame(preds, index=indices)\n",
    "ultimo_cliente['sent_label'] = pred_df['label']\n",
    "ultimo_cliente['sent_score'] = pred_df['score']\n",
    "\n",
    "# Extrai dígito de 'X star(s)'\n",
    "ultimo_cliente['sent_stars'] = (\n",
    "    ultimo_cliente['sent_label'].str.extract(r'(\\d)').astype(int)\n",
    ")\n",
    "\n",
    "ultimo_cliente[['tweet_id', 'sent_label', 'sent_stars']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9fca759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts distribution:\n",
      "sent_stars\n",
      "1    36132\n",
      "2     1926\n",
      "3     3968\n",
      "4     1744\n",
      "5    10828\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target_bin distribution (0/1, sem 3):\n",
      "target_bin\n",
      "0    38058\n",
      "1    12572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating target variables (Binary (0 (Unsatisfied), 1 (Satisfied), NaN (Neutral)), Multiclass (Insatisfied, Neutral, Satisfied))\n",
    "def map_bin(stars):\n",
    "    if stars <= 2:\n",
    "        return 0\n",
    "    if stars >= 4:\n",
    "        return 1\n",
    "    return np.nan\n",
    "\n",
    "ultimo_cliente['target_bin'] = ultimo_cliente['sent_stars'].apply(map_bin)\n",
    "\n",
    "ultimo_cliente['target_multi'] = ultimo_cliente['sent_stars'].map({\n",
    "    1: 'Unsatisfied',\n",
    "    2: 'Unsatisfied',\n",
    "    3: 'Neutral',\n",
    "    4: 'Satisfied',\n",
    "    5: 'Satisfied'\n",
    "})\n",
    "\n",
    "# Conjunto para treino binário (sem neutros)\n",
    "train_bin = ultimo_cliente.dropna(subset=['target_bin']).copy()\n",
    "train_bin['target_bin'] = train_bin['target_bin'].astype(int)\n",
    "\n",
    "print('Starts distribution:')\n",
    "print(ultimo_cliente['sent_stars'].value_counts().sort_index())\n",
    "\n",
    "print('\\nTarget_bin distribution (0/1, sem 3):')\n",
    "print(train_bin['target_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bfcda34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação das colunas em `bin_train`:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50630 entries, 0 to 54597\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype              \n",
      "---  ------                          --------------  -----              \n",
      " 0   conversation_id                 50630 non-null  Int64              \n",
      " 1   tweet_id                        50630 non-null  Int64              \n",
      " 2   created_at                      50630 non-null  datetime64[ns, UTC]\n",
      " 3   text                            50630 non-null  object             \n",
      " 4   text_clean                      50630 non-null  object             \n",
      " 5   total_duration_minutes          50630 non-null  float64            \n",
      " 6   time_to_first_response_minutes  539 non-null    float64            \n",
      " 7   sent_label                      50630 non-null  object             \n",
      " 8   sent_score                      50630 non-null  float64            \n",
      " 9   sent_stars                      50630 non-null  int64              \n",
      " 10  target_bin                      50630 non-null  int64              \n",
      " 11  target_multi                    50630 non-null  object             \n",
      "dtypes: Int64(2), datetime64[ns, UTC](1), float64(3), int64(2), object(4)\n",
      "memory usage: 5.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Atualizando o bin_train com as novas features\n",
    "# O `ultimo_cliente` já possui as colunas de tempo\n",
    "# Recriamos `bin_train` para garantir que ele também as tenha.\n",
    "bin_train = ultimo_cliente.dropna(subset=['target_bin']).copy()\n",
    "bin_train['target_bin'] = bin_train['target_bin'].astype(int)\n",
    "\n",
    "print(\"Verificação das colunas em `bin_train`:\")\n",
    "print(bin_train.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c07e2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)     # mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)     # hashtags\n",
    "    text = re.sub(r\"\\s+\", \" \", text)     # extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "ultimo_cliente['text_clean'] = ultimo_cliente['text_clean'].apply(clean_text)\n",
    "bin_train['text_clean'] = bin_train['text_clean'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4698f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving results\n",
    "import fastparquet\n",
    "\n",
    "\n",
    "\n",
    "ultimo_cliente.to_parquet('../data/preprocessed/client_tweets.parquet', index=False, engine='fastparquet')\n",
    "train_bin.to_parquet('../data/preprocessed/train_bin.parquet', index=False, engine='fastparquet')\n",
    "stats = {\n",
    "    \"n_observations_original\": len(data_sample),\n",
    "    \"n_observations_final\": len(ultimo_cliente),\n",
    "    \"distribution_sent_stars\": ultimo_cliente['sent_stars'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"../data/preprocessed/eda_stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ef7b3",
   "metadata": {},
   "source": [
    "## Combinação de Features e Preparação Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b9c9e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing dependencies\n",
    "%pip install -q sentence-transformers\n",
    "%pip install -q scikit-learn\n",
    "\n",
    "# Importing dependencies\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "# Ensuring output directories exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../data/preprocessed', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "898be0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured features processed. Shape: (50630, 12)\n"
     ]
    }
   ],
   "source": [
    "# Selecting the DataFrame for final preprocessing\n",
    "# We will use `bin_train`, which does not contain null values in the target variable\n",
    "\n",
    "final_df = bin_train.copy()\n",
    "\n",
    "# Defining columns by type\n",
    "numeric_features = [\n",
    "    'total_duration_minutes', 'time_to_first_response_minutes', 'sent_score'\n",
    "]\n",
    "text_feature = 'text_clean'\n",
    "target_col = 'target_bin'\n",
    "id_cols = ['conversation_id', 'tweet_id']\n",
    "\n",
    "# Pipeline for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# ColumnTransformer to apply different transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns (text, id, etc.)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to structured features\n",
    "structured_features_processed = preprocessor.fit_transform(final_df)\n",
    "\n",
    "processed_feature_names = numeric_features\n",
    "\n",
    "print(f\"Structured features processed. Shape: {structured_features_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aac91714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arthur\\Documents\\Cursor\\Projeto\\NLP\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arthur\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1583/1583 [17:05<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings generated. Shape: (50630, 512)\n",
      "\\nFinal preprocessed DataFrame (first rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_duration_minutes</th>\n",
       "      <th>time_to_first_response_minutes</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>target_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.025527</td>\n",
       "      <td>-0.134344</td>\n",
       "      <td>-0.025764</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>-0.063932</td>\n",
       "      <td>-0.032378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014949</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>-0.01401</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>-0.039484</td>\n",
       "      <td>-0.058814</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.025527</td>\n",
       "      <td>-0.073158</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>-0.044466</td>\n",
       "      <td>-0.020651</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>-0.008755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006713</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.037573</td>\n",
       "      <td>-0.027671</td>\n",
       "      <td>-0.040251</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.051989</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.025527</td>\n",
       "      <td>-0.098847</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.032789</td>\n",
       "      <td>0.033059</td>\n",
       "      <td>-0.020575</td>\n",
       "      <td>-0.043776</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020298</td>\n",
       "      <td>-0.035196</td>\n",
       "      <td>0.061651</td>\n",
       "      <td>-0.064578</td>\n",
       "      <td>0.058077</td>\n",
       "      <td>0.056611</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.025527</td>\n",
       "      <td>0.566254</td>\n",
       "      <td>0.015077</td>\n",
       "      <td>-0.02334</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>-0.021939</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.026524</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069496</td>\n",
       "      <td>0.062662</td>\n",
       "      <td>-0.00727</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>0.050734</td>\n",
       "      <td>0.030722</td>\n",
       "      <td>-0.034816</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.025527</td>\n",
       "      <td>-0.21144</td>\n",
       "      <td>-0.032982</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>-0.021147</td>\n",
       "      <td>-0.008958</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>-0.086024</td>\n",
       "      <td>-0.025065</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.048573</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  total_duration_minutes time_to_first_response_minutes sent_score     emb_0  \\\n",
       "0              -0.006434                      -0.025527  -0.134344 -0.025764   \n",
       "1              -0.006434                      -0.025527  -0.073158 -0.027546   \n",
       "2              -0.006434                      -0.025527  -0.098847  0.002533   \n",
       "3              -0.006434                      -0.025527   0.566254  0.015077   \n",
       "4              -0.006434                      -0.025527   -0.21144 -0.032982   \n",
       "\n",
       "      emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  ...   emb_505  \\\n",
       "0  0.031075  0.005968  0.013011 -0.042477 -0.063932 -0.032378  ...  0.014949   \n",
       "1 -0.044466 -0.020651  0.033756 -0.018774 -0.021676 -0.008755  ... -0.006713   \n",
       "2  0.045608  0.032789  0.033059 -0.020575 -0.043776 -0.067642  ... -0.020298   \n",
       "3  -0.02334  0.035434 -0.021939 -0.009099 -0.026524  0.003372  ...  0.069496   \n",
       "4  0.013207  0.021564  0.007199 -0.021147 -0.008958 -0.001474  ... -0.000058   \n",
       "\n",
       "    emb_506   emb_507   emb_508   emb_509   emb_510   emb_511 conversation_id  \\\n",
       "0  0.009421  0.006726  -0.01401  0.047852 -0.039484 -0.058814              12   \n",
       "1 -0.028638 -0.037573 -0.027671 -0.040251  0.056657  0.051989              69   \n",
       "2 -0.035196  0.061651 -0.064578  0.058077  0.056611  0.023738              84   \n",
       "3  0.062662  -0.00727 -0.002056  0.050734  0.030722 -0.034816             149   \n",
       "4  0.004172 -0.086024 -0.025065  0.069067  0.002457 -0.048573             208   \n",
       "\n",
       "  tweet_id target_bin  \n",
       "0       12          1  \n",
       "1       69          0  \n",
       "2       84          0  \n",
       "3      149          0  \n",
       "4      208          0  \n",
       "\n",
       "[5 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nPreprocessor saved in: ../models/preprocessor.joblib\n",
      "Final preprocessed DataFrame saved in: ../data/preprocessed/preprocessed_customer_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Loading the model for text embeddings\n",
    "# Using a multilingual model for robustness\n",
    "model_name = 'distiluse-base-multilingual-cased-v1'\n",
    "text_embedder = SentenceTransformer(model_name)\n",
    "\n",
    "# Generating text embeddings\n",
    "\n",
    "print(\"Generating text embeddings...\")\n",
    "text_embeddings = text_embedder.encode(\n",
    "    final_df[text_feature].tolist(),\n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(f\"Text embeddings generated. Shape: {text_embeddings.shape}\")\n",
    "\n",
    "# O `ColumnTransformer` manteve as colunas restantes no final do array.\n",
    "# Do `structured_features_processed`, queremos apenas as partes numéricas.\n",
    "structured_only_processed = structured_features_processed[:, :len(processed_feature_names)]\n",
    "\n",
    "# Combinando features estruturadas e embeddings de texto\n",
    "final_features_array = np.hstack([\n",
    "    structured_only_processed,\n",
    "    text_embeddings\n",
    "])\n",
    "\n",
    "# Criando o DataFrame final\n",
    "embedding_feature_names = [f'emb_{i}' for i in range(text_embeddings.shape[1])]\n",
    "final_column_names = processed_feature_names + embedding_feature_names\n",
    "\n",
    "preprocessed_df = pd.DataFrame(final_features_array, columns=final_column_names)\n",
    "\n",
    "# Adicionando de volta os IDs e a variável alvo\n",
    "preprocessed_df[id_cols] = final_df[id_cols].values\n",
    "preprocessed_df[target_col] = final_df[target_col].values\n",
    "\n",
    "print(\"\\\\nFinal preprocessed DataFrame (first rows):\")\n",
    "display(preprocessed_df.head())\n",
    "\n",
    "# --- Saving artifacts ---\n",
    "\n",
    "# 1. Save the ColumnTransformer\n",
    "preprocessor_path = '../models/preprocessor.joblib'\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"\\\\nPreprocessor saved in: {preprocessor_path}\")\n",
    "\n",
    "# The SentenceTransformer model is loaded from the Hub, so we don't need to save it\n",
    "# locally, just remember the `model_name`.\n",
    "\n",
    "# 2. Save the final DataFrame\n",
    "output_path = '../data/preprocessed/preprocessed_customer_data.parquet'\n",
    "preprocessed_df.to_parquet(output_path, index=False)\n",
    "print(f\"Final preprocessed DataFrame saved in: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
